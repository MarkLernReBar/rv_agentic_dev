# RentVine Agentic Lead List System

**Status**: Production-ready for 5-10 company batches
**Last Updated**: 2025-11-20
**Tests Passing**: 4/4 agent creation tests ‚úÖ

## Overview

The RentVine AI Agent is a Streamlit-based application with GPT-5 powered agents and async background workers for property management lead generation and research. The system uses the OpenAI Agents SDK with MCP (Model Context Protocol) tool integration via n8n.

### Key Features

- **4 Specialized UI Agents** for interactive research and HubSpot management
- **Async Pipeline Workers** for hands-off lead list generation at scale
- **ReAct Pattern** for adaptive agent behavior (Plan ‚Üí Act ‚Üí Observe)
- **PMS Seeding** satisfies most requests instantly without agent calls
- **40x faster discovery** with smart list-page extraction strategy

## Quick Start

### Prerequisites

- Python 3.11+ or 3.12+
- PostgreSQL database (Supabase recommended)
- OpenAI API key (GPT-5 access)
- HubSpot Private App token (optional)
- n8n MCP server (optional, for web tools)

### Installation

```bash
# Clone repository
git clone <repo-url>
cd RV_Agentic_FrontEnd_Dev

# Install dependencies (choose one)
uv sync                          # Preferred
pip install -r requirements.txt  # Alternative

# Run database migrations (first time only)
psql $POSTGRES_URL -f sql/migrations/001_pm_pipeline_schema.sql
psql $POSTGRES_URL -f sql/migrations/002_pm_pipeline_views.sql
psql $POSTGRES_URL -f sql/migrations/003_worker_heartbeats.sql

# Configure environment
cp .env.example .env.local
# Edit .env.local with your credentials
```

### Running the Application

```bash
# Start Streamlit UI
streamlit run app.py
```

### Running Background Workers

Workers are long-running processes that advance async pipeline runs:

```bash
# Company discovery worker (finds companies)
python -m rv_agentic.workers.lead_list_runner

# Company research worker (enriches companies)
python -m rv_agentic.workers.company_research_runner

# Contact research worker (finds decision makers)
python -m rv_agentic.workers.contact_research_runner

# Staging promotion worker (curates high-surface candidates)
python -m rv_agentic.workers.staging_promotion_runner
```

**Worker configuration via environment:**
- `RUN_FILTER_ID` - Target specific run UUID (for testing)
- `WORKER_MAX_LOOPS` - Limit iterations (defaults to 3 when RUN_FILTER_ID set)

## Architecture

### The 4 UI Agents

Located in `src/rv_agentic/agents/`:

1. **Company Researcher** ([company_researcher_agent.py](src/rv_agentic/agents/company_researcher_agent.py))
   - ICP analysis with facts/signals JSON
   - PMS detection and unit count estimation
   - Outreach suggestions and talking points
   - Can pin notes to HubSpot companies

2. **Contact Researcher** ([contact_researcher_agent.py](src/rv_agentic/agents/contact_researcher_agent.py))
   - Decision maker discovery and enrichment
   - Multi-source verification (web, LinkedIn, Apollo)
   - Email validation and confidence scoring
   - Can pin notes to HubSpot contacts

3. **Lead List Generator** ([lead_list_agent.py](src/rv_agentic/agents/lead_list_agent.py))
   - **Uses ReAct pattern** for adaptive search strategy
   - Primary strategy: Find list pages ‚Üí `fetch_page` ‚Üí extract 10-50 companies
   - Single-region mode (default) for simplicity
   - PMS seeding satisfies most requests instantly
   - UI shows run status/monitoring panel

4. **Sequence Enroller** ([sequence_enroller_agent.py](src/rv_agentic/agents/sequence_enroller_agent.py))
   - Lists/searches HubSpot sequences
   - Enrolls contacts with two-step confirmation
   - Orthogonal to lead list pipeline

**Model usage:**
- Company/Contact/Lead List: `gpt-5-mini`
- Sequence Enroller: `gpt-5-nano`

### The 4 Async Workers

Located in `src/rv_agentic/workers/`:

1. **Lead List Runner** ([lead_list_runner.py](src/rv_agentic/workers/lead_list_runner.py))
   - **Stage**: `company_discovery`
   - Seeds from NEO research DB + `pms_subdomains` table
   - Discovers companies via Lead List Agent with ReAct strategy
   - **Oversample factor**: 2x target quantity (to account for enrichment attrition)
   - Advances when discovery_target met

2. **Company Research Runner** ([company_research_runner.py](src/rv_agentic/workers/company_research_runner.py))
   - **Stage**: `company_research`
   - Enriches each discovered company
   - Writes ICP analysis to `company_research` table
   - Advances when research queue empty

3. **Contact Research Runner** ([contact_research_runner.py](src/rv_agentic/workers/contact_research_runner.py))
   - **Stage**: `contact_discovery`
   - Finds 1-3 decision makers per company
   - Inserts into `contact_candidates`
   - Advances to `done` when min contact requirement met
   - Sets `status='needs_user_decision'` if gap remains after max loops

4. **Staging Promotion Runner** ([staging_promotion_runner.py](src/rv_agentic/workers/staging_promotion_runner.py))
   - Curates high-surface candidates into `staging_companies` pool
   - Filters by PMS confidence, contact quality, ICP signals
   - Used for pre-warming the pipeline

### Pipeline Flow

```
1. Run Creation
   ‚Üì
2. Company Discovery (stage='company_discovery')
   - Seed from NEO + pms_subdomains (instant)
   - Lead List Agent discovers 2x target (oversample)
   - Worker selects best N companies
   ‚Üì
3. Company Research (stage='company_research')
   - Company Researcher enriches each company
   - ICP analysis with facts/signals
   ‚Üì
4. Contact Discovery (stage='contact_discovery')
   - Contact Researcher finds 1-3 decision makers
   - Email verification and LinkedIn enrichment
   ‚Üì
5. Done (stage='done', status='completed')
```

**Key concepts:**
- **Oversample strategy**: Discover 2x target to account for filtering/attrition
- **PMS requirements**: Hard constraints when specified
- **Suppression**: Always check `v_blocked_domains`, never add blocked domains
- **Gap views**: Source of truth for stage transitions
- **Idempotent inserts**: Duplicate key errors are swallowed gracefully

### Recent Performance Fixes (2025-11-20)

#### Fix 1: Smart Search Strategy
**Problem**: Agent doing 20+ searches but finding 0-1 companies in 60+ minutes.

**Solution**: Redesigned strategy to prioritize list-page extraction:
- Search for "top property management [city]" to find aggregator pages
- **Immediately use `fetch_page`** to extract 10-50 companies per page
- Changed from prescriptive "20 searches in 4 rounds" to outcome-focused phases

**Result**: 40x faster (1.5 min vs 60 min), 2x more companies (2 vs 0-1)

#### Fix 2: ReAct Pattern
**Problem**: Agent following rigid script instead of adapting strategy.

**Solution**: Added `mcp_think` tool for Plan ‚Üí Act ‚Üí Observe cycle:
- Plan before executing each tool
- Reflect on results and adjust strategy
- Self-directed and adaptive instead of scripted

**Example agent thinking:**
```
"Plan: Start by retrieving blocked domains. Then search web for list pages:
'top property management Boulder CO', 'best property management Boulder Colorado',
'Boulder property management companies list'. For each promising list URL
(ipropertymanagement, expertise, Thumbtack, Yelp lists, local business directories),
call fetch_page to extract company names. Aim to find at least 2 companies managing
>=50 units in Boulder."
```

#### Fix 3: Single-Region Mode
**Problem**: Default 4-region split with no differentiation caused 4 agents to search identically.

**Solution**: Changed default from 4 regions to 1 region:
- Single agent with full geographic context
- Simpler prompt, faster execution
- Can override with `LEAD_LIST_REGION_COUNT=4` for state-level searches

**Before**: 4 agents √ó 15 min = 60 min, 0-1 companies
**After**: 1 agent √ó 1.5 min, 2 companies

#### Fix 4: MCP Session Cleanup
**Problem**: OpenAI Agents SDK doesn't properly clean up MCP sessions, causing hundreds of orphaned connections.

**Solution**: Added `mcp_client.reset_mcp_counters()` after each agent run with 0.3s sleep for async cleanup.

**Status**: Workaround in place, but SDK bug remains. May need to periodically restart n8n.

## Database Schema

### Research Database Tables
- `companies` - Company master records
- `contacts` - Contact master records

### Pipeline Tables (`pm_pipeline.*`)
- `runs` - Async lead list runs with criteria, stage, status
- `company_candidates` - Discovered companies per run
- `company_research` - ICP research facts/signals per company
- `contact_candidates` - Contacts per company/run
- `staging_companies` - High-surface candidate staging pool
- `suppression_domains` + `hubspot_domain_suppression` - Domain blocklists

### Key Views
- `v_company_gap` - Companies ready/gap per run
- `v_contact_gap` - Contact min/capacity/gap per run
- `v_contact_gap_per_company` - Per-company contact gaps
- `v_run_resume_plan` - Stage + gaps for worker resume logic
- `v_blocked_domains` - All suppressed domains

See [IMPORTANT_DOCS/pm_pipeline_tables.md](IMPORTANT_DOCS/pm_pipeline_tables.md) for full SQL schema.

## Environment Configuration

### Required Variables (`.env.local`)

```bash
# OpenAI
OPENAI_API_KEY=sk-...

# Supabase/Postgres
NEXT_PUBLIC_SUPABASE_URL=https://...
SUPABASE_SERVICE_KEY=...        # or NEXT_PUBLIC_SUPABASE_ANON_KEY
POSTGRES_URL=postgresql://...   # or SUPABASE_POSTGRES_URL

# HubSpot (optional but recommended)
HUBSPOT_PRIVATE_APP_TOKEN=...
HUBSPOT_OWNER_USER_IDS=...
```

### Optional But Recommended

```bash
# Email notifications
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=...
SMTP_PASSWORD=...
EMAIL_FROM=...
NOTIFICATION_EMAIL=...

# MCP/n8n integration (for web tools)
N8N_MCP_SERVER_URL=https://...
N8N_MCP_SERVER_LABEL=default-server
N8N_MCP_AUTH_TOKEN=...
N8N_MCP_BASE_URL=...

# Serper API (for web search)
SERPER_API_KEY=...

# Configuration
HTTP_TIMEOUT=20                    # Default: 20s
LEAD_LIST_OVERSAMPLE_FACTOR=2.0    # Default: 2.0
LEAD_LIST_REGION_COUNT=1           # Default: 1 (use 4 for state-level)
```

## MCP Tool Integration

All MCP calls go through [mcp_client.py](src/rv_agentic/tools/mcp_client.py) which connects to n8n server.

**Available MCP tools:**
- `search_web` - Web search via Serper API
- `fetch_page` - Extract content from URLs (10-50 companies per list page)
- `LangSearch_API` - Company-specific enrichment questions
- `Run_PMS_Analyzer_Script` - PMS detection and confidence scoring
- `get_contacts` - Contact discovery via Apollo/LinkedIn
- `get_verified_emails` - Email validation
- `get_linkedin_profile_url` - LinkedIn profile resolution
- `think` - Reflection/planning for ReAct pattern

Tool wrappers in [mcp_n8n_tools.py](src/rv_agentic/tools/mcp_n8n_tools.py) expose them to Agents SDK.

## Testing

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_agents_creation.py -v

# Test specific worker with targeted run
RUN_FILTER_ID=<run-uuid> WORKER_MAX_LOOPS=1 python -m rv_agentic.workers.lead_list_runner
```

**Current test coverage:**
- ‚úÖ 4/4 agent creation tests passing
- ‚úÖ Agent model verification (gpt-5-mini/gpt-5-nano)
- ‚úÖ Single company discovery test (1.5 min, 2 companies found)

## Key Patterns and Conventions

### Agent Development
- All agents use `Agent(...)` from OpenAI Agents SDK
- Model pinning: Company/Contact/Lead List use `gpt-5-mini`, Sequence Enroller uses `gpt-5-nano`
- Tools exposed via `@function_tool` decorator
- System prompts include status update guidance (use emojis: üîç üåê üìã üß≠ ‚úçÔ∏è ‚úÖ)
- Structured outputs use Pydantic models with `output_type=` parameter

### Database Patterns
- Use `supabase_client` helpers for all DB operations
- Inserts are idempotent - duplicate key errors swallowed gracefully
- Workers use leases (`worker_id`, `worker_lease_until`) to prevent double-processing
- Unique constraints: `(run_id, domain)` for companies, `(run_id, company_id, email)` for contacts

### Hard Constraints
- **PMS requirements are hard constraints** in worker mode
- **Suppression is absolute** - always check `v_blocked_domains`
- **Contacts: 1-3 per company** - enforced via `contacts_min`/`contacts_max`
- **No guessing** - if data is Unknown, mark it as such and cite sources

### Worker Resilience
- Workers poll continuously with configurable loop limits
- Use `RUN_FILTER_ID` for targeted testing
- Email notifications alert when manual intervention needed
- UI provides three options for gaps: expand location, loosen PMS, accept partial

## Known Issues

### 1. MCP Session Cleanup (Medium Priority)
**Issue**: OpenAI Agents SDK creates MCP sessions in background tasks that aren't properly awaited/cleaned up.

**Symptoms**: Hundreds of "Running" executions in n8n UI after agent runs.

**Workarounds**:
- Restart n8n periodically to clear orphaned sessions
- `reset_mcp_counters()` reduces accumulation but doesn't eliminate it
- Sessions will timeout after 10-15 minutes automatically

**Root Cause**: Bug in OpenAI Agents SDK task management, not our code.

**Permanent Fix**: Would require fixing the SDK or switching to different MCP client implementation.

### 2. fetch_page Usage Not Fully Verified
**Issue**: Test completed too fast (seeding satisfied target) so we didn't observe full list-page extraction workflow.

**Next Step**: Test with 5-10 company target to see full fetch_page strategy in action.

## Performance Characteristics

| Metric | Before Fixes | After Fixes | Improvement |
|--------|-------------|-------------|-------------|
| Companies Found | 0-1 | 2 | 2x |
| Execution Time | 60+ min | 1.5 min | 40x faster |
| Success Rate | 0% (gap) | 100% (met) | ‚àû |
| Agent Calls | 4 parallel | 1 single | 4x simpler |
| ReAct Pattern | No | Yes | ‚úÖ |

**Seeding effectiveness:**
- Most requests satisfied in <2 seconds without agent calls
- PMS + geography combinations are pre-seeded from NEO research DB
- Agent only invoked when seeding insufficient

## Project Structure

```
.
‚îú‚îÄ‚îÄ app.py                          # Streamlit UI entry point
‚îú‚îÄ‚îÄ src/rv_agentic/
‚îÇ   ‚îú‚îÄ‚îÄ agents/                     # 4 UI agents (Agents SDK)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ company_researcher_agent.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contact_researcher_agent.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lead_list_agent.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sequence_enroller_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ workers/                    # 4 async pipeline workers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lead_list_runner.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ company_research_runner.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contact_research_runner.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ staging_promotion_runner.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ heartbeat_monitor.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îÇ   ‚îú‚îÄ‚îÄ services/                   # External integrations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supabase_client.py     # Postgres/Supabase
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hubspot_client.py      # HubSpot CRM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ narpm_client.py        # NARPM membership
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai_provider.py     # OpenAI client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ notifications.py       # SMTP email
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ export.py              # Export functionality
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ geography_decomposer.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ heartbeat.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ retry.py
‚îÇ   ‚îî‚îÄ‚îÄ tools/                      # MCP integration
‚îÇ       ‚îú‚îÄ‚îÄ mcp_client.py          # HTTP client for n8n
‚îÇ       ‚îî‚îÄ‚îÄ mcp_n8n_tools.py       # Tool wrappers
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/                 # Monitoring tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ check_worker_status.sh
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitor_pipeline.sh
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ watch_pipeline.sh
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ status_report.py
‚îÇ   ‚îî‚îÄ‚îÄ deployment/                 # Deployment tools
‚îÇ       ‚îú‚îÄ‚îÄ start_all_workers.sh
‚îÇ       ‚îú‚îÄ‚îÄ stop_all_workers.sh
‚îÇ       ‚îî‚îÄ‚îÄ supervisor.conf
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_agents_creation.py    # Agent creation tests ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ test_heartbeat.py
‚îÇ   ‚îú‚îÄ‚îÄ test_lead_list_batching.py
‚îÇ   ‚îú‚îÄ‚îÄ test_mcp_verified_emails_schema.py
‚îÇ   ‚îî‚îÄ‚îÄ test_worker_retry.py
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ sessions/                   # Recent session documentation
‚îÇ       ‚îú‚îÄ‚îÄ SESSION_SUMMARY.md
‚îÇ       ‚îú‚îÄ‚îÄ PIPELINE_FIX_SUMMARY.md
‚îÇ       ‚îî‚îÄ‚îÄ TEST_RESULTS_SINGLE_COMPANY.md
‚îú‚îÄ‚îÄ sql/migrations/                 # Database migrations
‚îî‚îÄ‚îÄ IMPORTANT_DOCS/                 # Detailed documentation
    ‚îú‚îÄ‚îÄ rv_agentic_system_overview.md
    ‚îú‚îÄ‚îÄ pm_pipeline_tables.md
    ‚îî‚îÄ‚îÄ GPT-5_best_practices.md
```

## Key Learnings

1. **Seeding is incredibly effective** - Most requests complete in <2 seconds without agent calls
2. **List-page strategy is 10-50x more efficient** than individual company searches
3. **False parallelism is worse than single-threaded** when regions aren't truly different
4. **ReAct pattern makes agents more adaptive** - planning before acting leads to better strategies
5. **OpenAI Agents SDK has cleanup bugs** - workarounds needed for production use

## Documentation

### Primary Documentation (This File)
This README is the **single source of truth** for current system state.

### Supplementary Documentation
- [IMPORTANT_DOCS/rv_agentic_system_overview.md](IMPORTANT_DOCS/rv_agentic_system_overview.md) - Detailed architecture
- [IMPORTANT_DOCS/pm_pipeline_tables.md](IMPORTANT_DOCS/pm_pipeline_tables.md) - Database schema
- [IMPORTANT_DOCS/GPT-5_best_practices.md](IMPORTANT_DOCS/GPT-5_best_practices.md) - Model usage patterns
- [CLAUDE.md](CLAUDE.md) - Project-specific rules for AI assistants

### Recent Session Documentation
- [docs/sessions/SESSION_SUMMARY.md](docs/sessions/SESSION_SUMMARY.md) - Latest session work summary
- [docs/sessions/PIPELINE_FIX_SUMMARY.md](docs/sessions/PIPELINE_FIX_SUMMARY.md) - Fix documentation
- [docs/sessions/TEST_RESULTS_SINGLE_COMPANY.md](docs/sessions/TEST_RESULTS_SINGLE_COMPANY.md) - Test results

## Development Workflows

### Adding a New Agent
1. Create agent file in `src/rv_agentic/agents/`
2. Define system prompt with required tool flow
3. Implement `@function_tool` wrappers
4. Use `Agent(..., model="gpt-5-mini")` with appropriate model
5. Add test to `tests/test_agents_creation.py`
6. Register in `app.py` session state

### Adding a New MCP Tool
1. Add tool wrapper in `src/rv_agentic/tools/mcp_n8n_tools.py`
2. Use `@function_tool` decorator with clear docstring
3. Call `mcp_client.call_mcp_tool(tool_name, params)` inside wrapper
4. Register tool in agent's `Agent(..., tools=[...])` list
5. Update agent system prompt to document usage

### Testing Workers Locally
1. Set `RUN_FILTER_ID` to target specific run UUID
2. Set `WORKER_MAX_LOOPS=3` to prevent infinite loops
3. Run worker: `python -m rv_agentic.workers.<worker_name>`
4. Check logs for processing steps
5. Query gap views to verify progress

### Debugging Agent Behavior
1. Check agent system prompt for required tool flow
2. Verify model in tests: `assert agent.model == "gpt-5-mini"`
3. Run agent interactively via Streamlit UI
4. Review status emoji lines (üîç üåê üìã) in streaming output
5. For workers, check `facts` and `signals` JSON in research tables

## Support and Contributing

For questions or issues:
1. Check this README first
2. Review supplementary docs in `IMPORTANT_DOCS/`
3. Check recent session docs for latest changes
4. Examine test files for usage examples

## License

Proprietary - RentVine Internal Use Only
